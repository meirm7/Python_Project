{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python Project by Meir Moshkovitz.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meirm7/Python_Project/blob/master/Python_Project_by_Meir_Moshkovitz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU5eh78EEHTM",
        "colab_type": "text"
      },
      "source": [
        "# Background:\n",
        "The JSON data interchange format is getting more and more widely used today for data transfer via servers communication (e.g. in web services) , for database data storage communication etc.\n",
        "\n",
        "The basic syntactic structure of JASON is the following: JSON has two basic data structures: object and arrays. an object is a set of name:value pairs and an array is an ordered list of values. In general, these objects and arrays may contain other objects and arrays; hence, general JSON data package has a tree-like structure.\n",
        "\n",
        "according to JSON syntax rules (see JSON.org), white characters and particularly new line delimiters may be included in the the JSON formatted string, between certain elements (but not within value string literals), but they are ignored.\n",
        "However, for various reasons, the line delimiters sometimes are not preseneted or even intentionally removed (cleaned) from the stream.\n",
        "For example, because they, occasionally may disturb some parsers etc. especially when the streams are being processed automatically without human involvement.\n",
        "In such cases they are also just redundant and reduce the efficiency of the payload data transfer. For the discussion, we will call JSON streams without new line delimiters: \"flat JSON streams/strings\".\n",
        "(Remark: there is a different meaning to the term 'flat JASON' which pertains to the tree structure form of the stream; this meaning will not be used here.)\n",
        "But ,of course, in order to to be  human understandable, a flat JSON stream should be processed by slicing and indenting it so that it would be presented in the it's well known *nested* form.\n",
        "\n",
        "## Purpose\n",
        "\n",
        "In light of all this, the purpose of this project is to get an input flat-JSON string, analyse it and implement two processing functions:\n",
        "\n",
        "1) Present it in the human readable nested form, which clearly demonstrate it's underlying tree structure.\n",
        "\n",
        "2) Extract a requested value, embedded in the string, by specifying the 'path' to it in the string's underlying JSON tree structue.\n",
        "\n",
        "## Program organization\n",
        "\n",
        "All this functionality will be embedded within a class called JSONAnalyzer, which will get the flat JSON string as it's input, and implement the following two class methods:\n",
        "\n",
        "* print_nested()\n",
        "\n",
        "* extract_value_by_path(requested path)\n",
        "\n",
        "\n",
        "Following is the class implementation:\n",
        "\n",
        "## Class Implementation:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M5_jMHBIQ43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\"\"\"\n",
        "  =========================================================================\n",
        "  Author:  Meir Moshkovitz\n",
        "  \n",
        "  Subject: Analyzer program of flat JSON formatted stream/file.\n",
        "  Date:    December 2019\n",
        "  Course:  Data Scince.\n",
        "  \n",
        "  * Submitted as the final Project in the Python part of the course.\n",
        "  =========================================================================\n",
        "\n",
        "  Disclaimer:\n",
        "  This software was designed to be used only for private learning purposes.\n",
        "  Any use or copying of this software or part of it, is not allowed.\n",
        "  This software comes with no warranties of any kind whatsoever.\n",
        "  =========================================================================\n",
        "\"\"\"\n",
        "        \n",
        "class JSONAnalyzer:\n",
        "    \"\"\"Class or analyziong flat JSON formatted streams. \"\"\"\n",
        "\n",
        "    OBJ_BEGIN =       '{'\n",
        "    OBJ_END =         '}'\n",
        "    ARR_BEGIN =       '['\n",
        "    ARR_END =         ']'\n",
        "    NAME_SEPARATOR =  ':'\n",
        "    VALUE_SEPARATOR = ','\n",
        "    QUOTATION_MARKS = '\"'\n",
        "    \n",
        "    def __init__(self, json_str):\n",
        "        self.json_str = json_str\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.json_str\n",
        "    \n",
        "    def indent(n):\n",
        "        \"\"\"Indents a single line to the requested position. \"\"\"\n",
        "        print(n*' ', end = '')\n",
        "\n",
        "\n",
        "    def print_nested(self):\n",
        "        \"\"\"Prints the input flat JSON string in a human-readable indented form. \"\"\"\n",
        "        pStart = 0\n",
        "        depth = 0\n",
        "    \n",
        "        for i in range(len(self.json_str)):\n",
        "            if self.json_str[i] == JSONAnalyzer.OBJ_BEGIN:\n",
        "                pStop = i+1\n",
        "                JSONAnalyzer.indent(depth*4)\n",
        "                depth += 1\n",
        "            elif self.json_str[i] == JSONAnalyzer.OBJ_END:\n",
        "                pStop = i\n",
        "                JSONAnalyzer.indent(depth*4)\n",
        "                depth -= 1\n",
        "            elif self.json_str[i] == JSONAnalyzer.VALUE_SEPARATOR:\n",
        "                pStop = i+1\n",
        "                JSONAnalyzer.indent(depth*4)\n",
        "            elif self.json_str[i] == JSONAnalyzer.ARR_BEGIN:\n",
        "                pStop = i+1\n",
        "                JSONAnalyzer.indent(depth*4)\n",
        "                depth += 1\n",
        "            elif self.json_str[i] == JSONAnalyzer.ARR_END:\n",
        "                pStop = i\n",
        "                JSONAnalyzer.indent(depth*4)\n",
        "                depth -= 1        \n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            print(self.json_str[pStart:pStop])\n",
        "            pStart = pStop\n",
        "\n",
        "        print('}')\n",
        "\n",
        "#=============================================================================================\n",
        "\n",
        "\n",
        "    def clear_tags(tags):\n",
        "        \"\"\"Clears the auxiiary 'tags' list. \"\"\"\n",
        "        for i in range(len(tags)):\n",
        "            tags[i] = ''\n",
        "\n",
        "\n",
        "    def test_detected_tag(tags, depth, tag, value_tags_path):\n",
        "        \"\"\"Upon detection of a new name tag, checks whether the requested path location is met. \"\"\"\n",
        "        tags[depth] = tag\n",
        "\n",
        "        #just to improve performance\n",
        "        for i in range(1, len(value_tags_path)):\n",
        "            if tags[i] == '':\n",
        "                return False\n",
        "    \n",
        "        return (tags[:len(value_tags_path)] == value_tags_path) and (depth == len(value_tags_path) - 1 )\n",
        "\n",
        "    \n",
        "        \n",
        "    def find_value_len(s):\n",
        "        \"\"\"Calculates the length of the found value string. \"\"\"\n",
        "        i = 0\n",
        "        nested = True\n",
        "    \n",
        "        while s[i] == ' ':\n",
        "            i += 1\n",
        "        \n",
        "        opener = s[i]\n",
        "        if opener == JSONAnalyzer.QUOTATION_MARKS:\n",
        "            closer = opener\n",
        "        elif opener == JSONAnalyzer.OBJ_BEGIN:\n",
        "            closer = JSONAnalyzer.OBJ_END\n",
        "        elif opener == JSONAnalyzer.ARR_BEGIN:\n",
        "            closer = JSONAnalyzer.ARR_END\n",
        "        else:\n",
        "            nested = False\n",
        "\n",
        "        if(nested):    \n",
        "            nesting = 1\n",
        "            for i in range(i+1 , len(s)):\n",
        "                if s[i] == closer:\n",
        "                    nesting -= 1\n",
        "                elif s[i] == opener:\n",
        "                    nesting += 1\n",
        "\n",
        "                if nesting == 0:\n",
        "                    return i+1\n",
        "        else: # not nested\n",
        "            for i in range(i+1 , len(s)):\n",
        "                if s[i] == JSONAnalyzer.VALUE_SEPARATOR or\\\n",
        "                   s[i] == JSONAnalyzer.ARR_END or\\\n",
        "                   s[i] == JSONAnalyzer.OBJ_END:\n",
        "                    return i\n",
        "\n",
        "        \n",
        "    def extract_value_by_path(self, value_tags_path):\n",
        "        \"\"\"Extracts the requested value string from the JSON stream by it's tag names path in the JSON tree. \"\"\"\n",
        "        pStart = 0\n",
        "        pStop = 0\n",
        "        depth = 0\n",
        "        tag_expected = True\n",
        "        inside_tag = False\n",
        "        keep_looping = True\n",
        "        value_start = 0\n",
        "        JSON_MAX_DEPTH = 20\n",
        "        val_occurrences = 0\n",
        "        extracted_values =[]\n",
        "\n",
        "        value_tags_path = [''] + value_tags_path\n",
        "        tags = ['' for i in range(JSON_MAX_DEPTH)]\n",
        "  \n",
        "        JSONAnalyzer.clear_tags(tags)\n",
        "    \n",
        "        for i in range(len(self.json_str)):\n",
        "            if not keep_looping:\n",
        "                break\n",
        "        \n",
        "            if self.json_str[i] == JSONAnalyzer.OBJ_BEGIN:\n",
        "                pStop = i+1\n",
        "                depth += 1\n",
        "                tag_expected = True\n",
        "            elif self.json_str[i] == JSONAnalyzer.OBJ_END:\n",
        "                pStop = i\n",
        "                tags[depth] = ''\n",
        "                depth -= 1\n",
        "            elif self.json_str[i] == JSONAnalyzer.VALUE_SEPARATOR:\n",
        "                pStop = i+1\n",
        "                tag_expected = True\n",
        "            elif self.json_str[i] == JSONAnalyzer.QUOTATION_MARKS:\n",
        "                if tag_expected:\n",
        "                    tag_start = i+1\n",
        "                    tag_expected = False\n",
        "                    inside_tag = True\n",
        "                elif inside_tag:\n",
        "                    tag_end = i\n",
        "                    tag_found = JSONAnalyzer.test_detected_tag(tags, depth, self.json_str[tag_start:tag_end], value_tags_path)\n",
        "                    inside_tag = False\n",
        "                continue\n",
        "            elif self.json_str[i] == JSONAnalyzer.NAME_SEPARATOR:\n",
        "                if tag_found:\n",
        "                    value_start = i+1\n",
        "\n",
        "                    vl = JSONAnalyzer.find_value_len(self.json_str[value_start:])\n",
        "                \n",
        "                    extracted_values.append(self.json_str[value_start:value_start+vl])\n",
        "                    val_occurrences += 1\n",
        "                \n",
        "                    # keep_looping = False  #i.e. not greedy\n",
        "                continue    \n",
        "            continue\n",
        "\n",
        "            pStart = pStop\n",
        "        \n",
        "        return val_occurrences, extracted_values\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZw_WGwBLOLk",
        "colab_type": "text"
      },
      "source": [
        "## Class invocation demonstration:\n",
        "\n",
        "In order to demonstrate the usage and invocation of the class, we will use the following three example flat JSON packages (stored in files):\n",
        "\n",
        "1) quiz.json - represents the details of simple school quiz\n",
        "\n",
        "2) colors.json - represents the defining parameters of some colors\n",
        "\n",
        "3) glossary.json - represents the attributes of a glossary\n",
        "\n",
        "First, we'll import the files to colab:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s797tkFeHxs9",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw4AUmbQFKlh",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### **Example #1:   Analysis of *quiz.json* data package:**\n",
        "First, we'll open the quiz.json file:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mscl0nsHFNId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('quiz.json') as f:\n",
        "    quiz_stream = f.read()\n",
        "\n",
        "J = JSONAnalyzer(quiz_stream)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BkvkNaGJq05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#J = JSONAnalyzer('{\"quiz\": {\"sport\": {\"q1\": {\"question\": \"Which one is correct team name in NBA?\",\"options\":[\"New York Bulls\",\"Los Angeles Kings\",\"Golden State Warriros\",\"Huston Rocket\"],\"answer\": \"Huston Rocket\"}},\"maths\": {\"q1\": {\"question\": \"5 + 7 = ?\",\"options\":[\"10\",\"11\",\"12\",\"13\"],\"answer\": \"12\"},\"q2\": {\"question\": \"12 - 8 = ?\",\"options\":[\"1\",\"2\",\"3\",\"4\"],\"answer\": \"4\"}}}}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xigpL6ITMGPz",
        "colab_type": "text"
      },
      "source": [
        "( The very class object string representation have, naturally, set to the respective JSON stream itself; so, let's print it:)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SycqQ4c0KuET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Flat JSON stream:\\n',J)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV38xRRDI8hn",
        "colab_type": "text"
      },
      "source": [
        "Now, let's see it in nested form:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlOsuS4fLbBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('The respective nested stream is:\\n')\n",
        "J.print_nested()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm5rellIOAy5",
        "colab_type": "text"
      },
      "source": [
        "Now, let's extract various values from it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj6zW460JDP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "value_occurrences, values_extracted = J.extract_value_by_path(['quiz', 'sport' ,'q1', 'options'])\n",
        "\n",
        "print(f'found {value_occurrences} value occurrences.\\n')\n",
        "print('Found value(s):\\n')\n",
        "for value in values_extracted:\n",
        "  print(value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4toP_GaVH_wJ",
        "colab_type": "text"
      },
      "source": [
        "=================================================================================================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PNhVxgOOIGkT"
      },
      "source": [
        "\n",
        "### **Example #2:   Analysis of *colors.json* data package:**\n",
        "First, we'll open the colors.json file:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0Hd_Fw8wIhdW",
        "colab": {}
      },
      "source": [
        "with open('colors.json') as f:\n",
        "    colors_stream = f.read()\n",
        "\n",
        "J = JSONAnalyzer(colors_stream)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKJdmKOAKg_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#J = JSONAnalyzer('{\"colors\": [{\"color\": \"black\",\"category\": \"hue\",\"type\": \"primary\",\"code\": {\"rgba\": [255,255,255,1],\"hex\": \"#000\"}},{\"color\": \"white\",\"category\": \"value\",\"code\": {\"rgba\": [0,0,0,1],\"hex\": \"#FFF\"}},{\"color\": \"red\",\"category\": \"hue\",\"type\": \"primary\",\"code\": {\"rgba\": [255,0,0,1],\"hex\": \"#FF0\"}},{\"color\": \"blue\",\"category\": \"hue\",\"type\": \"primary\",\"code\": {\"rgba\": [0,0,255,1],\"hex\": \"#00F\"}},{\"color\": \"yellow\",\"category\": \"hue\",\"type\": \"primary\",\"code\": {\"rgba\": [255,255,0,1],\"hex\": \"#FF0\"}},{\"color\": \"green\",\"category\": \"hue\",\"type\": \"secondary\",\"code\": {\"rgba\": [0,255,0,1],\"hex\": \"#0F0\"}},]}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J4OsatV3M6Bz"
      },
      "source": [
        "( The very class object string representation have, naturally, been set to the respective JSON stream itself; so, let's print it: )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hna9npm9K54e",
        "colab": {}
      },
      "source": [
        "print('Flat JSON stream:\\n',J)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m5n0VohHNMi2"
      },
      "source": [
        "Now, let's see it in nested form:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OaGR8jR1Nowe",
        "colab": {}
      },
      "source": [
        "print('The respective nested stream is:\\n')\n",
        "J.print_nested()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HX_zPR2fOZY_"
      },
      "source": [
        "Now, let's extract various values from it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6XhF7G2OOqOj",
        "colab": {}
      },
      "source": [
        "value_occurrences, values_extracted = J.extract_value_by_path(['colors', 'color'])\n",
        "\n",
        "print(f'found {value_occurrences} value occurrences.\\n')\n",
        "print('Found value(s):\\n')\n",
        "for value in values_extracted:\n",
        "  print(value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3OygNrKPQD8",
        "colab_type": "text"
      },
      "source": [
        "================================================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "weMFriUVPhCA"
      },
      "source": [
        "\n",
        "### **Example #3:   Analysis of *glossary.json* data package:**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4NQQN9kP7AA",
        "colab_type": "text"
      },
      "source": [
        "First, we'll open the glossary.json file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BXmS_21gQJaT",
        "colab": {}
      },
      "source": [
        "with open('glossary.json') as f:\n",
        "    quiz_stream = f.read()\n",
        "\n",
        "J = JSONAnalyzer(quiz_stream)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FvHuGn0_RYif",
        "colab": {}
      },
      "source": [
        "#J = JSONAnalyzer('{\"glossary\": {\"title\": \"example glossary\",\"GlossDiv\": {\"title\": \"S\",\"GlossList\": {\"GlossEntry\": {\"ID\": \"SGML\",\"SortAs\": \"SGML\",\"GlossTerm\": \"Standard Generalized Markup Language\",\"Acronym\": \"SGML\",\"Abbrev\": \"ISO 8879:1986\",\"GlossDef\": {\"para\": \"A meta-markup language; used to create markup languages such as DocBook.\",\"GlossSeeAlso\": [\"GML\", \"XML\"]},\"GlossSee\": \"markup\"}}}}}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EcMfwvi0SgAV"
      },
      "source": [
        "( The very class object string representation have, naturally, been set to the respective JSON stream itself; so, let's print it:)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1WLm2e3TSo6b",
        "colab": {}
      },
      "source": [
        "print('Flat JSON stream:\\n',J)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CnDbYc2lS4iZ"
      },
      "source": [
        "Now, let's see it in nested form:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6h75BY4PTA3i",
        "colab": {}
      },
      "source": [
        "print('The respective nested stream is:\\n')\n",
        "J.print_nested()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9uGJHgNQTgJB"
      },
      "source": [
        "Now, let's extract various values from it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L-vOgsdZTuhu",
        "colab": {}
      },
      "source": [
        "value_occurrences, values_extracted = J.extract_value_by_path(['glossary', 'GlossDiv' ,'GlossList', 'GlossEntry', 'GlossDef', 'para'])\n",
        "\n",
        "print(f'found {value_occurrences} value occurrences.\\n')\n",
        "print('Found value(s):\\n')\n",
        "for value in values_extracted:\n",
        "  print(value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h43t6VlUbfW",
        "colab_type": "text"
      },
      "source": [
        "=================================================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHo6ZFj6Ugub",
        "colab_type": "text"
      },
      "source": [
        "=================================================================================================="
      ]
    }
  ]
}